{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 단어사전기반 분석\n",
    "- 감성사전을 이용하여 각 단어의 감정 분류와 그 정도를 알 수 있어야 함\n",
    "- 텍스트와 감성지수가 사전에 정의되어 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# pip install afinn\n",
    "from afinn import Afinn\n",
    "#imdb 데이터셋 5만건의 학습용,검증용 데이터셋 긍정,부정 리뷰로 라벨링되어 있음.\n",
    "#긍정리뷰데이터 20번째 내용\n",
    "# glob.glob 특정한 패턴의 파일만 선택하는 함수\n",
    "pos_review=(glob.glob(\"c:/data/imdb/train/pos/*.txt\"))[20]\n",
    "f = open(pos_review, 'r')\n",
    "#파일을 읽음\n",
    "lines1 = f.readlines()[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#감성분석 객체\n",
    "afinn = Afinn()\n",
    "#텍스트 전처리 후 감성점수 산출\n",
    "afinn.score(lines1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/data/imdb/train/pos\\\\0_9.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10000_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10001_10.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10002_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10003_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10004_8.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10005_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10006_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10007_7.txt',\n",
       " 'c:/data/imdb/train/pos\\\\10008_7.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/data/imdb/train/pos/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "2.0\n",
      "19.0\n",
      "3.0\n",
      "14.0\n",
      "8.0\n",
      "22.0\n",
      "28.0\n",
      "13.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 긍정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() #감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "f.close()\n",
    "#부정리뷰데이터 20번째 내용\n",
    "neg_review=(glob.glob(\"c:/data/imdb/train/neg/*.txt\"))[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(neg_review, 'r')\n",
    "lines2 = f.readlines()[0]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn.score(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:/data/imdb/train/neg\\\\0_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10000_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10001_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10002_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10003_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10004_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10005_3.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10006_4.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10007_1.txt',\n",
       " 'c:/data/imdb/train/neg\\\\10008_2.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=list(glob.glob('c:/data/imdb/train/neg/*.txt')[:10])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "-4.0\n",
      "9.0\n",
      "5.0\n",
      "-7.0\n",
      "1.0\n",
      "13.0\n",
      "4.0\n",
      "7.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "#학습용 부정리뷰 10개 파일만 테스트\n",
    "afinn=Afinn() #감성분석 함수\n",
    "for i in files:\n",
    "    f=open(i) #파일 오픈\n",
    "    lines1=f.readlines()[0] #리스트의 첫번째 문자열\n",
    "    print(afinn.score(lines1)) #감성점수\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 기계학습으로 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "#긍정 텍스트 로딩\n",
    "pos_review=(glob.glob(\"c:/data/imdb/train/pos/*.txt\")[:100])\n",
    "lines_pos=[]\n",
    "for i in pos_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_pos.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#부정 텍스트 로딩\n",
    "neg_review=(glob.glob(\"c:/data/imdb/train/neg/*.txt\")[:100])\n",
    "lines_neg=[]\n",
    "for i in neg_review:\n",
    "    try:\n",
    "        f = open(i, 'r')\n",
    "        temp = f.readlines()[0]\n",
    "        lines_neg.append(temp)\n",
    "        f.close()\n",
    "    except :\n",
    "        continue\n",
    "len(lines_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#긍정,부정 리뷰를 합침\n",
    "total_text=lines_pos+lines_neg\n",
    "len(total_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "#긍정,부정 클래스 라벨링\n",
    "x = np.array([\"pos\", \"neg\"])\n",
    "class_Index=np.repeat(x, [len(lines_pos), len(lines_neg)], axis=0)\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어들에 Tfidf 가중치를 부여한 후 문서-단어 매트릭스로 바꿈\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words=stop_words).fit(total_text)\n",
    "X_train_vectorized = vect.transform(total_text)\n",
    "X_train_vectorized.index = class_Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bromwell</th>\n",
       "      <th>high</th>\n",
       "      <th>cartoon</th>\n",
       "      <th>comedy</th>\n",
       "      <th>ran</th>\n",
       "      <th>time</th>\n",
       "      <th>programs</th>\n",
       "      <th>school</th>\n",
       "      <th>life</th>\n",
       "      <th>teachers</th>\n",
       "      <th>...</th>\n",
       "      <th>zombified</th>\n",
       "      <th>auteur</th>\n",
       "      <th>ample</th>\n",
       "      <th>opportunities</th>\n",
       "      <th>golden</th>\n",
       "      <th>geist</th>\n",
       "      <th>uttered</th>\n",
       "      <th>downloading</th>\n",
       "      <th>midget</th>\n",
       "      <th>tricking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bromwell  high  cartoon  comedy  ran  time  programs  school  life  \\\n",
       "0       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "1       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "2       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "3       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "4       0.0   0.0      0.0     0.0  0.0   0.0       0.0     0.0   0.0   \n",
       "\n",
       "   teachers  ...  zombified  auteur  ample  opportunities  golden  geist  \\\n",
       "0       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "1       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "2       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "3       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "4       0.0  ...        0.0     0.0    0.0            0.0     0.0    0.0   \n",
       "\n",
       "   uttered  downloading  midget  tricking  \n",
       "0      0.0          0.0     0.0       0.0  \n",
       "1      0.0          0.0     0.0       0.0  \n",
       "2      0.0          0.0     0.0       0.0  \n",
       "3      0.0          0.0     0.0       0.0  \n",
       "4      0.0          0.0     0.0       0.0  \n",
       "\n",
       "[5 rows x 6514 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#데이터프레임으로 변환\n",
    "df=pd.DataFrame(X_train_vectorized.toarray(), columns=vect.vocabulary_.keys())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#로지스틱 회귀 모형\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(random_state=10)\n",
    "logit.fit(X_train_vectorized, class_Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#긍정 리뷰들을 하나씩 불러와서 실험\n",
    "def pos_review(model):\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "    tests1=[]\n",
    "    for idx in range(0,num):\n",
    "        pos_review_test=(glob.glob(\"c:/data/imdb/test/pos/*.txt\"))[idx]\n",
    "        f = open(pos_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests1.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests1:\n",
    "        pred = model.predict(vect.transform(test))\n",
    "        result=pred[0]\n",
    "        if result==\"pos\":\n",
    "            count+=1\n",
    "        count_all += 1\n",
    "    rate= count*100/count_all\n",
    "    print(f\"분류정확도:{rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부정 리뷰들을 하나씩 불러와서 실험\n",
    "def neg_review(model):\n",
    "    count_all=0\n",
    "    count=0\n",
    "    num=100\n",
    "    tests2=[]\n",
    "    for idx in range(0,num):\n",
    "        neg_review_test=(glob.glob(\"c:/data/imdb/test/neg/*.txt\"))[idx]\n",
    "        f = open(neg_review_test, 'r',encoding=\"utf-8\")\n",
    "        tests2.append(f.readlines())\n",
    "        f.close()\n",
    "    for test in tests2:\n",
    "        preds = model.predict(vect.transform(test))\n",
    "        result=preds[0]\n",
    "        if result==\"neg\":\n",
    "            count+=1\n",
    "        count_all+=1\n",
    "    rate= count*100/count_all\n",
    "    print(\"예측정확도:{0:.1f}%\".format(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:66.0%\n",
      "예측정확도:82.0%\n"
     ]
    }
   ],
   "source": [
    "pos_review(logit)\n",
    "neg_review(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:54.0%\n",
      "예측정확도:54.0%\n"
     ]
    }
   ],
   "source": [
    "#의사결정나무 모형\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(X_train_vectorized, class_Index)\n",
    "pos_review(tree)\n",
    "neg_review(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:46.0%\n",
      "예측정확도:70.0%\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#10개의 트리로 구성된 랜덤 포레스트\n",
    "forest = RandomForestClassifier(n_estimators=10, random_state=10)\n",
    "forest.fit(X_train_vectorized, class_Index)\n",
    "pos_review(forest)\n",
    "neg_review(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:34.0%\n",
      "예측정확도:85.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train_vectorized, class_Index)\n",
    "pos_review(knn)\n",
    "neg_review(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:63.0%\n",
      "예측정확도:76.0%\n"
     ]
    }
   ],
   "source": [
    "#인공신경망\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=10)\n",
    "mlp.fit(X_train_vectorized, class_Index)\n",
    "pos_review(mlp)\n",
    "neg_review(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류정확도:63.0%\n",
      "예측정확도:86.0%\n"
     ]
    }
   ],
   "source": [
    "#SVM 모형\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=10)\n",
    "svm.fit(X_train_vectorized, class_Index)\n",
    "pos_review(svm)\n",
    "neg_review(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    ('What an awesome view', 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "test = [\n",
    "    ('The beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    ('I am not feeling dandy today.', 'neg'),\n",
    "    ('I feel amazing!', 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]\n",
    "cl = NaiveBayesClassifier(train)\n",
    "print(cl.classify('Their burgers are amazing'))\n",
    "print(cl.classify(\"I don't like their pizza.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#여러 문장을 종합하여 부정으로 분류\n",
    "blob = TextBlob(\"The beer was amazing. But the hangover was horrible. My boss was not happy.\", classifier=cl)\n",
    "blob.classify() # \"neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer was amazing. ==> pos\n",
      "But the hangover was horrible. ==> neg\n",
      "My boss was not happy. ==> neg\n",
      "The beer was good. ==> pos\n",
      "I do not enjoy my job ==> neg\n",
      "I am not feeling dandy today. ==> neg\n",
      "I feel amazing! ==> pos\n",
      "Gary is a friend of mine. ==> neg\n",
      "I can't believe I'm doing this. ==> neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#개별 문장으로 분류\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence, '==>', sentence.classify())\n",
    "# \"pos\", \"neg\", \"neg\"\n",
    "for row in test:\n",
    "    print(row[0],'==>', cl.classify(row[0]))\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(this) = True              neg : pos    =      2.3 : 1.0\n",
      "          contains(this) = False             pos : neg    =      1.8 : 1.0\n",
      "          contains(This) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "train = [\n",
    "    ('샌드위치 좋아해요', 'pos'),\n",
    "    ('너무 좋은 곳이예요', 'pos'),\n",
    "    ('너무 맛있어요', 'pos'),\n",
    "    ('내가 제일 좋아하는 곳이예요', 'pos'),\n",
    "    ('친한 친구예요', 'pos'),\n",
    "    ('이 사람은 믿을 수 없어요', 'neg'),\n",
    "    ('별로 안좋은 곳이네요', 'neg'),\n",
    "    (\"맛이 별로네요\", 'neg'),\n",
    "    ('경치가 별로예요', 'neg'),\n",
    "    ('별로 볼게 없네요', 'neg')\n",
    "]\n",
    "\n",
    "test = [\n",
    "    ('최고의 음료수', 'pos'),\n",
    "    ('별로 안좋아요', 'neg'),\n",
    "    ('이번주는 컨디션이 안좋아요', 'neg'),\n",
    "    ('너무 좋아요', 'pos'),\n",
    "    ('나와 가장 친해요', 'pos'),\n",
    "    (\"믿을 수 없어요\", 'neg')\n",
    "]\n",
    "\n",
    "cl = NaiveBayesClassifier(train)\n",
    "print(cl.classify('맛있는 음식이네요'))  \n",
    "print(cl.classify(\"피자맛이 별로네요\"))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"맛있는 음식이네요. 피자는 별로네요. 서비스는 좋네요.\", classifier=cl)\n",
    "blob.classify()  # \"neg\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맛있는 음식이네요. ==> pos\n",
      "피자는 별로네요. ==> neg\n",
      "서비스는 좋네요. ==> pos\n",
      "최고의 음료수 ==> pos\n",
      "별로 안좋아요 ==> neg\n",
      "이번주는 컨디션이 안좋아요 ==> pos\n",
      "너무 좋아요 ==> pos\n",
      "나와 가장 친해요 ==> pos\n",
      "믿을 수 없어요 ==> neg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence, '==>', sentence.classify())\n",
    "# \"pos\", \"neg\", \"neg\"\n",
    "for row in test:\n",
    "    print(row[0],'==>', cl.classify(row[0]))\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(곳이예요) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(너무) = False             neg : pos    =      1.6 : 1.0\n",
      "            contains(별로) = False             pos : neg    =      1.6 : 1.0\n",
      "           contains(경치가) = False             pos : neg    =      1.2 : 1.0\n",
      "          contains(곳이네요) = False             pos : neg    =      1.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
